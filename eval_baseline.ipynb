{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1e02806-2d0e-48d4-9240-4a82060dd885",
   "metadata": {},
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c2e821-0e52-4b26-82f2-78c6c26ff5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from database_interface import DatabaseHelper\n",
    "from collections import Counter\n",
    "MODEL_OUTPUT_PATH = \"/scratch/eecs595f25_class_root/eecs595f25_class/llada_data/synthetic_text_to_sql/output_sql.csv\"\n",
    "OUTPUT_FILE_PATH = \"/scratch/eecs595f25_class_root/eecs595f25_class/llada_data/synthetic_text_to_sql/valid_test.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8190c863-936c-4917-81c1-e9e7014909ef",
   "metadata": {},
   "source": [
    "## Load in initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f83404e6-ea11-4bf4-be75-43714722dded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieved dataset, info=Dataset({\n",
      "    features: ['id', 'domain', 'domain_description', 'sql_complexity', 'sql_complexity_description', 'sql_task_type', 'sql_task_type_description', 'sql_prompt', 'sql_context', 'sql', 'sql_explanation'],\n",
      "    num_rows: 3434\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "retrieved_dataset = load_dataset(\"json\", data_files=OUTPUT_FILE_PATH)[\"train\"]\n",
    "print(f\"retrieved dataset, info={retrieved_dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61dd892-62d3-4fae-bb94-0204dcb6d575",
   "metadata": {},
   "source": [
    "## Load and merge the results with the examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6acc55b-d25d-4bc3-bbd9-e4bb3ef34367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                                51\n",
      "out_sql            [\"\\nSELECT COUNT(*) AS number_of_patientsFROM ...\n",
      "sql_complexity                                           single join\n",
      "sql                SELECT COUNT(*) FROM patients INNER JOIN treat...\n",
      "sql_context        CREATE TABLE patients (id INT, country VARCHAR...\n",
      "sql_prompt         What is the number of patients in India who re...\n",
      "sql_explanation    First, we join the patients and treatments tab...\n",
      "Name: 29, dtype: object\n"
     ]
    }
   ],
   "source": [
    "model_res_df = pd.read_csv(MODEL_OUTPUT_PATH)\n",
    "gold_standard_df = retrieved_dataset.to_pandas()\n",
    "gold_standard_df = gold_standard_df.iloc[0:len(model_res_df)][[\n",
    "    'id',\n",
    "    'sql_complexity',\n",
    "    'sql',\n",
    "    'sql_context',\n",
    "    'sql_prompt',\n",
    "    'sql_explanation'\n",
    "    \n",
    "]]\n",
    "\n",
    "eval_df = pd.merge(model_res_df, gold_standard_df,on='id')\n",
    "# print(eval_df)\n",
    "print(eval_df.iloc[29])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a653900-3d8d-44ab-a35d-000cf4782df9",
   "metadata": {},
   "source": [
    "## Setup Bag-of-cells to do analysis of each data cell in outputs (Gemini provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53852cd3-36fc-4c16-912d-78b9cb7ca5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1 F1: 8.00 (P=4.00, R=4.00)\n",
      "Example 2 F1: 2.00 (P=1.00, R=1.00)\n"
     ]
    }
   ],
   "source": [
    "def get_cell_counts(df_gold, df_predicted):\n",
    "    \"\"\"\n",
    "    Calculates Precision, Recall, and F1 score based on a \n",
    "    \"Bag of Cells\" (multiset of all values).\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Flatten Gold DataFrame into a Counter ---\n",
    "    # .values.flatten() turns the whole DF into a 1D numpy array\n",
    "    # We must handle potential 'None' values which Counter might not like\n",
    "    gold_cells = Counter([str(v) for v in df_gold.values.flatten() if v is not None])\n",
    "    \n",
    "    # --- 2. Flatten Predicted DataFrame into a Counter ---\n",
    "    predicted_cells = Counter([str(v) for v in df_predicted.values.flatten() if v is not None])\n",
    "\n",
    "    # --- 3. Calculate Scores ---\n",
    "    \n",
    "    # Handle the \"divide by zero\" case if no cells are returned\n",
    "    total_gold = sum(gold_cells.values())\n",
    "    total_predicted = sum(predicted_cells.values())\n",
    "\n",
    "    # & (intersection) finds the element-wise minimum\n",
    "    intersection = gold_cells & predicted_cells\n",
    "    intersection_count = sum(intersection.values())\n",
    "    \n",
    "    # precision = intersection_count / total_predicted\n",
    "    # recall = intersection_count / total_gold\n",
    "        \n",
    "    return intersection_count, total_predicted, total_gold\n",
    "\n",
    "\n",
    "#test\n",
    "df_gold_1 = pd.DataFrame([[1.0, 2000.0], [1.0, 2000.0], [2.0, 4000.0], [2.0, 4000.0]])\n",
    "df_pred_1 = pd.DataFrame([[1.0, 2000.0], [2.0, 4000.0]])\n",
    "p, r, f1 = get_cell_counts(df_gold_1, df_pred_1)\n",
    "print(f\"Example 1 F1: {f1:.2f} (P={p:.2f}, R={r:.2f})\")\n",
    "\n",
    "\n",
    "df_gold_2 = pd.DataFrame([['Commercial', 70.0]])\n",
    "df_pred_2 = pd.DataFrame([[70.0]])\n",
    "p, r, f1 = get_cell_counts(df_gold_2, df_pred_2)\n",
    "print(f\"Example 2 F1: {f1:.2f} (P={p:.2f}, R={r:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee740e-4abc-46d2-bb53-575e24290aa6",
   "metadata": {},
   "source": [
    "## Iterate over examples and process the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6e8b619-4660-4a6a-b700-fa4d91de2dd3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'basic SQL': {'correct': 0, 'parsable': 0, 'total': 0, 'cell_intersect': 0, 'cell_predict': 1e-06, 'cell_gold': 1e-06}, 'aggregation': {'correct': 0, 'parsable': 0, 'total': 0, 'cell_intersect': 0, 'cell_predict': 1e-06, 'cell_gold': 1e-06}, 'window functions': {'correct': 0, 'parsable': 0, 'total': 0, 'cell_intersect': 0, 'cell_predict': 1e-06, 'cell_gold': 1e-06}, 'single join': {'correct': 0, 'parsable': 0, 'total': 0, 'cell_intersect': 0, 'cell_predict': 1e-06, 'cell_gold': 1e-06}, 'multiple_joins': {'correct': 0, 'parsable': 0, 'total': 0, 'cell_intersect': 0, 'cell_predict': 1e-06, 'cell_gold': 1e-06}, 'subqueries': {'correct': 0, 'parsable': 0, 'total': 0, 'cell_intersect': 0, 'cell_predict': 1e-06, 'cell_gold': 1e-06}, 'set operations': {'correct': 0, 'parsable': 0, 'total': 0, 'cell_intersect': 0, 'cell_predict': 1e-06, 'cell_gold': 1e-06}}\n",
      "DEBUG:\n",
      " Model res:\n",
      "Counter()\n",
      "Truth res:\n",
      "Counter({('Africa', nan): 1, ('Asia', nan): 1, (0.5, 'Europe'): 1})\n",
      "\n",
      "Prompt:What is the difference between the average satisfaction score of models trained on dataset D and dataset C, for each continent?\n",
      "SQL of res:  SELECT     continent,     AVG(satisfaction) AS avg_satisfaction_D FROM models AS_satisfaction_D WHERE dataset = 'datasetD' GROUP BY continent;  SELECT  continent,     AVG(satisfaction) AS avg_satisfaction_C FROM models AS_satisfaction_C WHERE dataset = 'datasetC' GROUP BY continent;  SELECT     continent,     avg_satisfaction_D - avg_satisfaction_C AS difference FROM AS_satisfaction_D JOIN AS_satisfaction_C ON AS_satisfaction_D.continent = AS_satisfaction_C.continent; \n",
      "SQL of truth: SELECT continent, AVG(m.satisfaction) - (SELECT AVG(satisfaction) FROM models m2 WHERE m.continent = m2.continent AND m2.dataset = 'datasetC') FROM models m WHERE m.dataset = 'datasetD' GROUP BY continent;\n",
      "SQL explanation: This query uses a subquery to find the average satisfaction score for models trained on dataset C, for each continent, and then subtracts that from the average satisfaction score for models trained on dataset D.\n",
      "---------\n",
      "DEBUG:\n",
      " Model res:\n",
      "Counter()\n",
      "Truth res:\n",
      "Counter({(1.0, 'Clothing', 'NY'): 1, (1.0, 'CA', 'Electronics'): 1, (1.0, 'Electronics', 'WA'): 1})\n",
      "\n",
      "Prompt:Determine the percentage of sales for each product category in each state\n",
      "SQL of res:  WITH      total_sales AS         SELECT              product_category,             state,             SUM(sales) AS total_sales         FROM              sales         GROUP BY              product_category, state ) SELECT      s.product_category,     s.state,     s.sales,     (s.sales / ts.total_sales) * 100 AS percentage_of_sales FROM      sales s JOIN      total_sales ts ON      s.product_category = ts.product_category     AND s.state = ts.state ORDER BY      s.product_category, s.state; \n",
      "SQL of truth: SELECT s1.product_category, s1.state, SUM(s1.sales) / (SELECT SUM(s2.sales) FROM sales s2 WHERE s2.state = s1.state) FROM sales s1 GROUP BY s1.product_category, s1.state;\n",
      "SQL explanation: Determine the percentage of sales for each product category in each state by dividing the total sales for each product category in each state by the total sales for each state, using a correlated subquery to calculate the total sales for each state.\n",
      "---------\n",
      "DEBUG:\n",
      " Model res:\n",
      "Counter()\n",
      "Truth res:\n",
      "Counter({('0.0%', 1, 'Asian'): 1, ('0.0%', 1, 'Black or African American'): 1, ('0.0%', 1, 'Hispanic or Latino'): 1, ('0.0%', 2, 'White'): 1})\n",
      "\n",
      "Prompt:What is the racial and ethnic diversity of the company?\n",
      "SQL of res:  --  SELECT      id,     name,     race,     ethnicity FROM      employees; \n",
      "SQL of truth: SELECT race, COUNT(*) as num_employees, CONCAT(ROUND(COUNT(*) / (SELECT COUNT(*) FROM employees) * 100, 2), '%') as percent_of_employees FROM employees GROUP BY race;\n",
      "SQL explanation: We count the number of employees in each racial category and calculate the percentage of the total workforce that each category represents. We then present the results in a table with one row for each racial category.\n",
      "---------\n",
      "DEBUG:\n",
      " Model res:\n",
      "Counter()\n",
      "Truth res:\n",
      "Counter({(None,): 1})\n",
      "\n",
      "Prompt:What is the total revenue for the top 5 dispensaries in Colorado in Q1 of 2023?\n",
      "SQL of res:  SELECT      dispensary_name,     SUM(revenue) AS total_revenue FROM      dispensary_sales WHERE      state = 'Colorado'     AND sale_date >= '2023-01-01'     AND sale_date <= '2023-03-31' GROUP BY      dispensary_name ORDER BY      total_revenue DESC LIMIT 5; \n",
      "SQL of truth: SELECT SUM(revenue) FROM dispensary_sales WHERE state = 'Colorado' AND sale_date BETWEEN '2023-01-01' AND '2023-03-31' AND dispensary_name IN (SELECT dispensary_name FROM dispensary_sales WHERE state = 'Colorado' AND sale_date BETWEEN '2023-01-01' AND '2023-03-31' GROUP BY dispensary_name ORDER BY SUM(revenue) DESC LIMIT 5);\n",
      "SQL explanation: This query calculates the total revenue for the top 5 dispensaries in Colorado in Q1 of 2023 by summing the revenue for all records where the dispensary_name is in the top 5 dispensaries with the highest revenue in Colorado in Q1 of 2023, filtering the dispensary_sales table for records with a matching state and sale_date in Q1 of 2023.\n",
      "---------\n",
      "DEBUG:\n",
      " Model res:\n",
      "Counter()\n",
      "Truth res:\n",
      "Counter({(110, 50, 60): 1})\n",
      "\n",
      "Prompt:Who has the highest number of rebounds for the Raptors?\n",
      "SQL of res:  SELECT away.team_name, away.away_team_rebounds FROM teams away JOIN games g ON g.away_team_id = away.team_id WHERE away.team_name = 'Raptors' ORDER BY away.away_team_rebounds DESC LIMIT 1; \n",
      "SQL of truth: SELECT home_team_rebounds, away_team_rebounds, (home_team_rebounds + away_team_rebounds) as total_rebounds FROM games WHERE home_team_id = (SELECT team_id FROM teams WHERE team_name = 'Raptors') OR away_team_id = (SELECT team_id FROM teams WHERE team_name = 'Raptors') ORDER BY total_rebounds DESC LIMIT 1;\n",
      "SQL explanation: The SQL query finds the total number of rebounds for the Raptors in each game and orders them in descending order. The query then returns the player with the highest number of rebounds.\n",
      "---------\n",
      "DEBUG:\n",
      " Model res:\n",
      "Counter()\n",
      "Truth res:\n",
      "Counter({(50.0,): 1})\n",
      "\n",
      "Prompt:What is the percentage of women in the Mining department?\n",
      "SQL of res:  SELECT      SUM(CASE WHEN WHEN Gender = 'Female' THEN 1 ELSE 0 END) AS WomenCount,     COUNT(*) AS TotalEmployees,     (CASE WHEN SUM(CASE WHEN Gender = 'Female' THEN 1 ELSE 0 END) = 0 THEN 0 ELSE (SUM(CASE WHEN Gender = 'Female' THEN 1 ELSE 0 END) / COUNT(*)) * 100 END) AS WomenPercentage FROM      Employees WHERE      Department = 'Mining'; \n",
      "SQL of truth: SELECT (COUNT(*) * 100.0 / (SELECT COUNT(*) FROM Employees WHERE Department = 'Mining')) AS Percentage FROM Employees WHERE Department = 'Mining' AND Gender = 'Female';\n",
      "SQL explanation: This SQL query calculates the percentage of women in the Mining department by using a subquery to get the total number of employees in the Mining department, then dividing the number of female employees in the Mining department by the total number of employees in the Mining department, multiplying the result by 100.0 to get a percentage.\n",
      "---------\n",
      "An error occurred: incomplete input, skipping insertion\n",
      "DEBUG:\n",
      " Model res:\n",
      "Counter()\n",
      "Truth res:\n",
      "Counter({(None,): 1})\n",
      "\n",
      "Prompt:What is the percentage of students who received accommodations for mobility impairments?\n",
      "SQL of res:  SELECT      ((DISTINCT COUNT(Dudent_id) / COUNT(DISTINCT department)) * 100 AS percentage_of_students_with_mobility_impairment  FROM      Students LEFT JOIN      Accommodations ON Students.student_id = Accommodations.student_id WHERE       Accommodations.accommodation_type = 'mobility impairment' GROUP BY      Students.department; \n",
      "SQL of truth: SELECT (COUNT(DISTINCT student_id) * 100.0 / (SELECT COUNT(DISTINCT student_id) FROM Students)) as percentage FROM Accommodations WHERE student_id IN ( SELECT student_id FROM DisabilityTypes WHERE disability_type = 'Mobility Impairment');\n",
      "SQL explanation: This query calculates the percentage of students who received accommodations for mobility impairments by dividing the count of students with mobility impairments who received accommodations by the total number of students. It uses a subquery to get the student IDs of those with mobility impairments.\n",
      "---------\n",
      "DEBUG:\n",
      " Model res:\n",
      "Counter()\n",
      "Truth res:\n",
      "Counter({(None,): 1})\n",
      "\n",
      "Prompt:What is the total duration of workout sessions for users who have completed at least 5 sessions of a specific workout type (e.g. cycling)?\n",
      "SQL of res:  SELECT      SUM(user_id) AS total_usersessions,     SUM(duration) AS total_duration FROM      workout_sessions_details WHERE      workout_type = 'Cycling' GROUP BY      user_id HAVING      COUNT(*) >= 5; \n",
      "SQL of truth: SELECT SUM(duration) FROM workout_sessions_details WHERE workout_type = 'Cycling' AND user_id IN (SELECT user_id FROM workout_sessions_details GROUP BY user_id HAVING COUNT(*) >= 5);\n",
      "SQL explanation: The query first identifies users who have completed at least 5 sessions of a specific workout type by grouping the workout_sessions_details table by user_id and filtering based on the count of sessions. The outer query then calculates the total duration of workout sessions among those users for the specified workout type.\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "sql_difficulty = eval_df['sql_complexity'].unique()\n",
    "complexity_eval_res = {complexity:{\"correct\":0, \"parsable\":0, \"total\":0, \"cell_intersect\":0, \"cell_predict\":0.000001, \"cell_gold\": 0.000001} for complexity in sql_difficulty}\n",
    "print(complexity_eval_res)\n",
    "count = 0\n",
    "for index, row in eval_df.iterrows():\n",
    "    model_sql_res = row.out_sql[1:len(row.out_sql)-1]\n",
    "    complexity = row.sql_complexity\n",
    "    complexity_eval_res[complexity]['total'] += 1\n",
    "    if model_sql_res != \"None\":\n",
    "        db_obj = DatabaseHelper(\":memory:\")\n",
    "        db_obj.insert_data(row.sql_context)\n",
    "        # Do minimal cleaning to pass the SQL\n",
    "        cleaned_sql = model_sql_res.strip().strip(\"'\").replace(\"\\\\n\",\" \").strip(\"\\\"\")\n",
    "        model_res, status = db_obj.fetch_data(cleaned_sql)\n",
    "        \n",
    "        # if status == \"failure\":\n",
    "        #     continue\n",
    "            \n",
    "        # If SQL parsed, increment score\n",
    "        complexity_eval_res[complexity]['parsable'] += 1\n",
    "#         if model_res.empty:\n",
    "#             # print(f\"ID:{index} -- SQL that caused error:\\n{model_sql_res}\\n\")\n",
    "#             continue\n",
    "            \n",
    "        truth_res, status = db_obj.fetch_data(row.sql)\n",
    "        # try:\n",
    "        model_res_normalized = Counter(\n",
    "            [tuple(sorted(row, key=str)) for row in model_res.values.tolist()]\n",
    "        )\n",
    "        truth_res_normalized = Counter(\n",
    "            [tuple(sorted(row, key=str)) for row in truth_res.values.tolist()]\n",
    "        )\n",
    "        # except Exception as e:\n",
    "        #     print(\"PARSING ISSUE\")\n",
    "        #     print(e)\n",
    "        #     print(\"DATA:\")\n",
    "        #     print(truth_res)\n",
    "        #     print(model_res)\n",
    "        if model_res_normalized != truth_res_normalized and complexity == \"subqueries\":\n",
    "            print(f\"DEBUG:\\n Model res:\\n{model_res_normalized}\\nTruth res:\\n{truth_res_normalized}\\n\")\n",
    "            print(f\"Prompt:{row.sql_prompt}\")\n",
    "            print(f\"SQL of res: {cleaned_sql}\")\n",
    "            print(f\"SQL of truth: {row.sql}\")\n",
    "            print(f\"SQL explanation: {row.sql_explanation}\")\n",
    "            print(\"---------\")\n",
    "        # Give correct point for results that are matched\n",
    "        # Note: This is a naive method which doesn't consider ORDER by. We will assume the non-ordered data considered 'correct'\n",
    "        \n",
    "        complexity_eval_res[complexity]['correct'] += 1 if model_res_normalized == truth_res_normalized else 0\n",
    "        # get cell matches\n",
    "        intersect_count, predict_count, gold_count = get_cell_counts(truth_res, model_res)\n",
    "    \n",
    "        # if complexity == \"subqueries\":\n",
    "        #     print(\"MODEL RES\")\n",
    "        #     print(model_res)\n",
    "        #     print(\"TRUTH RES\")\n",
    "        #     print(truth_res)\n",
    "        #     print(get_cell_counts(truth_res, model_res))\n",
    "        #     count += 1\n",
    "        #     print(\"number of subqueires considered:\",count)\n",
    "        complexity_eval_res[complexity]['cell_intersect'] += intersect_count\n",
    "        complexity_eval_res[complexity]['cell_predict'] += predict_count\n",
    "        complexity_eval_res[complexity]['cell_gold'] += gold_count\n",
    "        \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "722288c1-d620-43bd-9088-ff65121fcdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'basic SQL': {'correct': 120, 'parsable': 157, 'total': 577, 'cell_intersect': 230, 'cell_predict': 271.000001, 'cell_gold': 305.000001}, 'aggregation': {'correct': 39, 'parsable': 57, 'total': 234, 'cell_intersect': 242, 'cell_predict': 277.000001, 'cell_gold': 319.000001}, 'window functions': {'correct': 1, 'parsable': 12, 'total': 33, 'cell_intersect': 60, 'cell_predict': 88.000001, 'cell_gold': 115.000001}, 'single join': {'correct': 26, 'parsable': 45, 'total': 134, 'cell_intersect': 76, 'cell_predict': 109.000001, 'cell_gold': 115.000001}, 'multiple_joins': {'correct': 1, 'parsable': 6, 'total': 18, 'cell_intersect': 2, 'cell_predict': 2.000001, 'cell_gold': 29.000000999999997}, 'subqueries': {'correct': 3, 'parsable': 11, 'total': 48, 'cell_intersect': 4, 'cell_predict': 4.000001, 'cell_gold': 35.000001}, 'set operations': {'correct': 0, 'parsable': 2, 'total': 7, 'cell_intersect': 0, 'cell_predict': 1e-06, 'cell_gold': 12.000001000000001}}\n"
     ]
    }
   ],
   "source": [
    "print(complexity_eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61eea9f0-7aa7-4cde-b3b6-643a2eefa4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complexity: basic SQL, num. samples = 577\n",
      "   Macro stats -- correct:0.21 | parsable: 0.27\n",
      "   Cell stats -- precision:0.85 | recall:0.75 | F1: 0.7986111078398981\n",
      "Complexity: aggregation, num. samples = 234\n",
      "   Macro stats -- correct:0.17 | parsable: 0.24\n",
      "   Cell stats -- precision:0.87 | recall:0.76 | F1: 0.8120805336901321\n",
      "Complexity: window functions, num. samples = 33\n",
      "   Macro stats -- correct:0.03 | parsable: 0.36\n",
      "   Cell stats -- precision:0.68 | recall:0.52 | F1: 0.5911329986109831\n",
      "Complexity: single join, num. samples = 134\n",
      "   Macro stats -- correct:0.19 | parsable: 0.34\n",
      "   Cell stats -- precision:0.7 | recall:0.66 | F1: 0.6785714220131138\n",
      "Complexity: multiple_joins, num. samples = 18\n",
      "   Macro stats -- correct:0.056 | parsable: 0.33\n",
      "   Cell stats -- precision:1.0 | recall:0.069 | F1: 0.1290322496191472\n",
      "Complexity: subqueries, num. samples = 48\n",
      "   Macro stats -- correct:0.062 | parsable: 0.23\n",
      "   Cell stats -- precision:1.0 | recall:0.11 | F1: 0.2051281944247211\n",
      "Complexity: set operations, num. samples = 7\n",
      "   Macro stats -- correct:0.0 | parsable: 0.29\n",
      "   Cell stats -- precision:0.0 | recall:0.0 | F1: 0.0\n"
     ]
    }
   ],
   "source": [
    "for complexity, counts in complexity_eval_res.items():\n",
    "    print(f\"Complexity: {complexity}, num. samples = {counts['total']}\")\n",
    "    print(f\"   Macro stats -- correct:{counts['correct']/counts['total']:.2} | parsable: {counts['parsable']/counts['total']:.2}\")\n",
    "    precision = counts['cell_intersect']/counts['cell_predict']\n",
    "    recall = counts['cell_intersect']/counts['cell_gold']\n",
    "    print(f\"   Cell stats -- precision:{precision:.2} | recall:{recall:.2} | F1: {(2 * precision * recall) / (precision + recall+1e-9)}\")\n",
    "    # precision = intersection_count / total_predicted\n",
    "    #recall = intersection_count / total_gold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda:myenv311",
   "language": "python",
   "name": "myenv31"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
