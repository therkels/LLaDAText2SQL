{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24177ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import ContextPredictor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import load_dataset, Dataset, load_from_disk\n",
    "\n",
    "FIXED_BUCKETS = [16,32,48,64,96,128,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba80f07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ContextPredictor(\n",
       "  (bert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (seq): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (5): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    (6): GELU(approximate='none')\n",
       "    (7): Linear(in_features=64, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model = ContextPredictor.ContextPredictor(num_classes=len(FIXED_BUCKETS), bert_requires_grad=False)\n",
    "model.load_state_dict(torch.load('../saved_models/predictor_epoch_1.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c8a8bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"../data\"\n",
    "reloaded = load_from_disk(dataset_path)\n",
    "input_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "pred_tokenizer = AutoTokenizer.from_pretrained('GSAI-ML/LLaDA-8B-Instruct', trust_remote_code=True)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    tokenized = input_tokenizer(\n",
    "        example[\"sql_prompt\"],\n",
    "        example[\"sql_context\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    )\n",
    "    tokenized_target = pred_tokenizer(\n",
    "        example[\"sql\"],\n",
    "        truncation=False,\n",
    "        padding=False\n",
    "    )\n",
    "    sql_len = float(len(tokenized_target[\"input_ids\"]))\n",
    "    tokenized[\"labels\"] = sql_len\n",
    "    return tokenized\n",
    "\n",
    "tokenized_datasets = reloaded.map(tokenize_function, batched=False, remove_columns=reloaded[\"train\"].column_names)\n",
    "\n",
    "tokenized_datasets.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    ")\n",
    "\n",
    "eval_dataset = tokenized_datasets[\"test\"]\n",
    "\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    eval_dataset, batch_size=1, shuffle=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99509a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted SQL length: 16, Actual SQL length: 25.0 -- difference: 9.0\n",
      "Predicted SQL length: 48, Actual SQL length: 12.0 -- difference: 36.0\n",
      "Predicted SQL length: 32, Actual SQL length: 22.0 -- difference: 10.0\n",
      "Predicted SQL length: 32, Actual SQL length: 50.0 -- difference: 18.0\n",
      "Predicted SQL length: 16, Actual SQL length: 11.0 -- difference: 5.0\n",
      "Predicted SQL length: 16, Actual SQL length: 11.0 -- difference: 5.0\n",
      "Predicted SQL length: 32, Actual SQL length: 41.0 -- difference: 9.0\n",
      "Predicted SQL length: 32, Actual SQL length: 23.0 -- difference: 9.0\n",
      "Predicted SQL length: 32, Actual SQL length: 39.0 -- difference: 7.0\n",
      "Predicted SQL length: 32, Actual SQL length: 19.0 -- difference: 13.0\n",
      "Predicted SQL length: 48, Actual SQL length: 19.0 -- difference: 29.0\n",
      "Predicted SQL length: 48, Actual SQL length: 21.0 -- difference: 27.0\n",
      "Predicted SQL length: 48, Actual SQL length: 46.0 -- difference: 2.0\n",
      "Predicted SQL length: 48, Actual SQL length: 24.0 -- difference: 24.0\n",
      "Predicted SQL length: 32, Actual SQL length: 19.0 -- difference: 13.0\n",
      "Predicted SQL length: 32, Actual SQL length: 13.0 -- difference: 19.0\n",
      "Predicted SQL length: 32, Actual SQL length: 20.0 -- difference: 12.0\n",
      "Predicted SQL length: 32, Actual SQL length: 61.0 -- difference: 29.0\n",
      "Predicted SQL length: 32, Actual SQL length: 29.0 -- difference: 3.0\n",
      "Predicted SQL length: 32, Actual SQL length: 12.0 -- difference: 20.0\n",
      "Predicted SQL length: 32, Actual SQL length: 14.0 -- difference: 18.0\n",
      "Predicted SQL length: 32, Actual SQL length: 24.0 -- difference: 8.0\n",
      "Predicted SQL length: 48, Actual SQL length: 52.0 -- difference: 4.0\n",
      "Predicted SQL length: 32, Actual SQL length: 79.0 -- difference: 47.0\n",
      "Predicted SQL length: 32, Actual SQL length: 33.0 -- difference: 1.0\n",
      "Predicted SQL length: 48, Actual SQL length: 38.0 -- difference: 10.0\n",
      "Predicted SQL length: 48, Actual SQL length: 34.0 -- difference: 14.0\n",
      "Predicted SQL length: 48, Actual SQL length: 49.0 -- difference: 1.0\n",
      "Predicted SQL length: 32, Actual SQL length: 17.0 -- difference: 15.0\n",
      "Predicted SQL length: 48, Actual SQL length: 77.0 -- difference: 29.0\n",
      "Predicted SQL length: 48, Actual SQL length: 26.0 -- difference: 22.0\n",
      "Predicted SQL length: 32, Actual SQL length: 34.0 -- difference: 2.0\n",
      "Predicted SQL length: 32, Actual SQL length: 20.0 -- difference: 12.0\n",
      "Predicted SQL length: 32, Actual SQL length: 12.0 -- difference: 20.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 32, Actual SQL length: 44.0 -- difference: 12.0\n",
      "Predicted SQL length: 48, Actual SQL length: 23.0 -- difference: 25.0\n",
      "Predicted SQL length: 32, Actual SQL length: 14.0 -- difference: 18.0\n",
      "Predicted SQL length: 48, Actual SQL length: 29.0 -- difference: 19.0\n",
      "Predicted SQL length: 32, Actual SQL length: 39.0 -- difference: 7.0\n",
      "Predicted SQL length: 48, Actual SQL length: 16.0 -- difference: 32.0\n",
      "Predicted SQL length: 32, Actual SQL length: 20.0 -- difference: 12.0\n",
      "Predicted SQL length: 48, Actual SQL length: 19.0 -- difference: 29.0\n",
      "Predicted SQL length: 32, Actual SQL length: 28.0 -- difference: 4.0\n",
      "Predicted SQL length: 32, Actual SQL length: 31.0 -- difference: 1.0\n",
      "Predicted SQL length: 32, Actual SQL length: 31.0 -- difference: 1.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 32, Actual SQL length: 25.0 -- difference: 7.0\n",
      "Predicted SQL length: 32, Actual SQL length: 39.0 -- difference: 7.0\n",
      "Predicted SQL length: 32, Actual SQL length: 25.0 -- difference: 7.0\n",
      "Predicted SQL length: 16, Actual SQL length: 14.0 -- difference: 2.0\n",
      "Predicted SQL length: 32, Actual SQL length: 42.0 -- difference: 10.0\n",
      "Predicted SQL length: 32, Actual SQL length: 16.0 -- difference: 16.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 48, Actual SQL length: 23.0 -- difference: 25.0\n",
      "Predicted SQL length: 48, Actual SQL length: 24.0 -- difference: 24.0\n",
      "Predicted SQL length: 32, Actual SQL length: 16.0 -- difference: 16.0\n",
      "Predicted SQL length: 32, Actual SQL length: 17.0 -- difference: 15.0\n",
      "Predicted SQL length: 32, Actual SQL length: 26.0 -- difference: 6.0\n",
      "Predicted SQL length: 48, Actual SQL length: 32.0 -- difference: 16.0\n",
      "Predicted SQL length: 48, Actual SQL length: 8.0 -- difference: 40.0\n",
      "Predicted SQL length: 16, Actual SQL length: 16.0 -- difference: 0.0\n",
      "Predicted SQL length: 32, Actual SQL length: 12.0 -- difference: 20.0\n",
      "Predicted SQL length: 32, Actual SQL length: 42.0 -- difference: 10.0\n",
      "Predicted SQL length: 32, Actual SQL length: 24.0 -- difference: 8.0\n",
      "Predicted SQL length: 32, Actual SQL length: 28.0 -- difference: 4.0\n",
      "Predicted SQL length: 32, Actual SQL length: 13.0 -- difference: 19.0\n",
      "Predicted SQL length: 32, Actual SQL length: 19.0 -- difference: 13.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 32, Actual SQL length: 41.0 -- difference: 9.0\n",
      "Predicted SQL length: 32, Actual SQL length: 16.0 -- difference: 16.0\n",
      "Predicted SQL length: 32, Actual SQL length: 12.0 -- difference: 20.0\n",
      "Predicted SQL length: 16, Actual SQL length: 15.0 -- difference: 1.0\n",
      "Predicted SQL length: 32, Actual SQL length: 59.0 -- difference: 27.0\n",
      "Predicted SQL length: 48, Actual SQL length: 101.0 -- difference: 53.0\n",
      "Predicted SQL length: 32, Actual SQL length: 31.0 -- difference: 1.0\n",
      "Predicted SQL length: 48, Actual SQL length: 32.0 -- difference: 16.0\n",
      "Predicted SQL length: 32, Actual SQL length: 45.0 -- difference: 13.0\n",
      "Predicted SQL length: 32, Actual SQL length: 25.0 -- difference: 7.0\n",
      "Predicted SQL length: 48, Actual SQL length: 56.0 -- difference: 8.0\n",
      "Predicted SQL length: 32, Actual SQL length: 7.0 -- difference: 25.0\n",
      "Predicted SQL length: 32, Actual SQL length: 13.0 -- difference: 19.0\n",
      "Predicted SQL length: 48, Actual SQL length: 52.0 -- difference: 4.0\n",
      "Predicted SQL length: 32, Actual SQL length: 14.0 -- difference: 18.0\n",
      "Predicted SQL length: 32, Actual SQL length: 16.0 -- difference: 16.0\n",
      "Predicted SQL length: 48, Actual SQL length: 49.0 -- difference: 1.0\n",
      "Predicted SQL length: 48, Actual SQL length: 19.0 -- difference: 29.0\n",
      "Predicted SQL length: 32, Actual SQL length: 32.0 -- difference: 0.0\n",
      "Predicted SQL length: 16, Actual SQL length: 10.0 -- difference: 6.0\n",
      "Predicted SQL length: 32, Actual SQL length: 12.0 -- difference: 20.0\n",
      "Predicted SQL length: 32, Actual SQL length: 15.0 -- difference: 17.0\n",
      "Predicted SQL length: 16, Actual SQL length: 10.0 -- difference: 6.0\n",
      "Predicted SQL length: 32, Actual SQL length: 27.0 -- difference: 5.0\n",
      "Predicted SQL length: 32, Actual SQL length: 26.0 -- difference: 6.0\n",
      "Predicted SQL length: 32, Actual SQL length: 19.0 -- difference: 13.0\n",
      "Predicted SQL length: 32, Actual SQL length: 49.0 -- difference: 17.0\n",
      "Predicted SQL length: 32, Actual SQL length: 40.0 -- difference: 8.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 32, Actual SQL length: 19.0 -- difference: 13.0\n",
      "Predicted SQL length: 32, Actual SQL length: 26.0 -- difference: 6.0\n",
      "Predicted SQL length: 32, Actual SQL length: 24.0 -- difference: 8.0\n",
      "Predicted SQL length: 32, Actual SQL length: 23.0 -- difference: 9.0\n",
      "Predicted SQL length: 16, Actual SQL length: 14.0 -- difference: 2.0\n",
      "Predicted SQL length: 32, Actual SQL length: 20.0 -- difference: 12.0\n",
      "Predicted SQL length: 16, Actual SQL length: 17.0 -- difference: 1.0\n",
      "Predicted SQL length: 32, Actual SQL length: 22.0 -- difference: 10.0\n",
      "Predicted SQL length: 32, Actual SQL length: 22.0 -- difference: 10.0\n",
      "Predicted SQL length: 48, Actual SQL length: 45.0 -- difference: 3.0\n",
      "Predicted SQL length: 32, Actual SQL length: 25.0 -- difference: 7.0\n",
      "Predicted SQL length: 16, Actual SQL length: 11.0 -- difference: 5.0\n",
      "Predicted SQL length: 32, Actual SQL length: 18.0 -- difference: 14.0\n",
      "Predicted SQL length: 48, Actual SQL length: 51.0 -- difference: 3.0\n",
      "Predicted SQL length: 16, Actual SQL length: 13.0 -- difference: 3.0\n",
      "Predicted SQL length: 32, Actual SQL length: 29.0 -- difference: 3.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 48, Actual SQL length: 33.0 -- difference: 15.0\n",
      "Predicted SQL length: 32, Actual SQL length: 55.0 -- difference: 23.0\n",
      "Predicted SQL length: 32, Actual SQL length: 15.0 -- difference: 17.0\n",
      "Predicted SQL length: 32, Actual SQL length: 17.0 -- difference: 15.0\n",
      "Predicted SQL length: 32, Actual SQL length: 17.0 -- difference: 15.0\n",
      "Predicted SQL length: 32, Actual SQL length: 19.0 -- difference: 13.0\n",
      "Predicted SQL length: 32, Actual SQL length: 30.0 -- difference: 2.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 32, Actual SQL length: 24.0 -- difference: 8.0\n",
      "Predicted SQL length: 48, Actual SQL length: 21.0 -- difference: 27.0\n",
      "Predicted SQL length: 48, Actual SQL length: 27.0 -- difference: 21.0\n",
      "Predicted SQL length: 48, Actual SQL length: 28.0 -- difference: 20.0\n",
      "Predicted SQL length: 32, Actual SQL length: 15.0 -- difference: 17.0\n",
      "Predicted SQL length: 48, Actual SQL length: 15.0 -- difference: 33.0\n",
      "Predicted SQL length: 32, Actual SQL length: 19.0 -- difference: 13.0\n",
      "Predicted SQL length: 48, Actual SQL length: 31.0 -- difference: 17.0\n",
      "Predicted SQL length: 32, Actual SQL length: 19.0 -- difference: 13.0\n",
      "Predicted SQL length: 48, Actual SQL length: 51.0 -- difference: 3.0\n",
      "Predicted SQL length: 32, Actual SQL length: 17.0 -- difference: 15.0\n",
      "Predicted SQL length: 32, Actual SQL length: 40.0 -- difference: 8.0\n",
      "Predicted SQL length: 32, Actual SQL length: 54.0 -- difference: 22.0\n",
      "Predicted SQL length: 32, Actual SQL length: 23.0 -- difference: 9.0\n",
      "Predicted SQL length: 32, Actual SQL length: 17.0 -- difference: 15.0\n",
      "Predicted SQL length: 32, Actual SQL length: 12.0 -- difference: 20.0\n",
      "Predicted SQL length: 32, Actual SQL length: 27.0 -- difference: 5.0\n",
      "Predicted SQL length: 32, Actual SQL length: 32.0 -- difference: 0.0\n",
      "Predicted SQL length: 32, Actual SQL length: 22.0 -- difference: 10.0\n",
      "Predicted SQL length: 32, Actual SQL length: 26.0 -- difference: 6.0\n",
      "Predicted SQL length: 16, Actual SQL length: 12.0 -- difference: 4.0\n",
      "Predicted SQL length: 32, Actual SQL length: 18.0 -- difference: 14.0\n",
      "Predicted SQL length: 32, Actual SQL length: 19.0 -- difference: 13.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 32, Actual SQL length: 37.0 -- difference: 5.0\n",
      "Predicted SQL length: 32, Actual SQL length: 18.0 -- difference: 14.0\n",
      "Predicted SQL length: 32, Actual SQL length: 15.0 -- difference: 17.0\n",
      "Predicted SQL length: 32, Actual SQL length: 19.0 -- difference: 13.0\n",
      "Predicted SQL length: 32, Actual SQL length: 24.0 -- difference: 8.0\n",
      "Predicted SQL length: 48, Actual SQL length: 46.0 -- difference: 2.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 32, Actual SQL length: 18.0 -- difference: 14.0\n",
      "Predicted SQL length: 16, Actual SQL length: 24.0 -- difference: 8.0\n",
      "Predicted SQL length: 32, Actual SQL length: 24.0 -- difference: 8.0\n",
      "Predicted SQL length: 32, Actual SQL length: 30.0 -- difference: 2.0\n",
      "Predicted SQL length: 48, Actual SQL length: 42.0 -- difference: 6.0\n",
      "Predicted SQL length: 48, Actual SQL length: 27.0 -- difference: 21.0\n",
      "Predicted SQL length: 32, Actual SQL length: 22.0 -- difference: 10.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 32, Actual SQL length: 25.0 -- difference: 7.0\n",
      "Predicted SQL length: 48, Actual SQL length: 22.0 -- difference: 26.0\n",
      "Predicted SQL length: 48, Actual SQL length: 55.0 -- difference: 7.0\n",
      "Predicted SQL length: 32, Actual SQL length: 27.0 -- difference: 5.0\n",
      "Predicted SQL length: 32, Actual SQL length: 41.0 -- difference: 9.0\n",
      "Predicted SQL length: 32, Actual SQL length: 33.0 -- difference: 1.0\n",
      "Predicted SQL length: 48, Actual SQL length: 56.0 -- difference: 8.0\n",
      "Predicted SQL length: 32, Actual SQL length: 7.0 -- difference: 25.0\n",
      "Predicted SQL length: 32, Actual SQL length: 14.0 -- difference: 18.0\n",
      "Predicted SQL length: 32, Actual SQL length: 50.0 -- difference: 18.0\n",
      "Predicted SQL length: 32, Actual SQL length: 34.0 -- difference: 2.0\n",
      "Predicted SQL length: 32, Actual SQL length: 18.0 -- difference: 14.0\n",
      "Predicted SQL length: 32, Actual SQL length: 26.0 -- difference: 6.0\n",
      "Predicted SQL length: 48, Actual SQL length: 38.0 -- difference: 10.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 32, Actual SQL length: 24.0 -- difference: 8.0\n",
      "Predicted SQL length: 48, Actual SQL length: 30.0 -- difference: 18.0\n",
      "Predicted SQL length: 48, Actual SQL length: 50.0 -- difference: 2.0\n",
      "Predicted SQL length: 32, Actual SQL length: 19.0 -- difference: 13.0\n",
      "Predicted SQL length: 32, Actual SQL length: 22.0 -- difference: 10.0\n",
      "Predicted SQL length: 48, Actual SQL length: 42.0 -- difference: 6.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 32, Actual SQL length: 17.0 -- difference: 15.0\n",
      "Predicted SQL length: 32, Actual SQL length: 25.0 -- difference: 7.0\n",
      "Predicted SQL length: 48, Actual SQL length: 36.0 -- difference: 12.0\n",
      "Predicted SQL length: 32, Actual SQL length: 28.0 -- difference: 4.0\n",
      "Predicted SQL length: 32, Actual SQL length: 16.0 -- difference: 16.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 32, Actual SQL length: 29.0 -- difference: 3.0\n",
      "Predicted SQL length: 32, Actual SQL length: 16.0 -- difference: 16.0\n",
      "Predicted SQL length: 32, Actual SQL length: 29.0 -- difference: 3.0\n",
      "Predicted SQL length: 32, Actual SQL length: 30.0 -- difference: 2.0\n",
      "Predicted SQL length: 48, Actual SQL length: 42.0 -- difference: 6.0\n",
      "Predicted SQL length: 48, Actual SQL length: 42.0 -- difference: 6.0\n",
      "Predicted SQL length: 32, Actual SQL length: 25.0 -- difference: 7.0\n",
      "Predicted SQL length: 32, Actual SQL length: 13.0 -- difference: 19.0\n",
      "Predicted SQL length: 32, Actual SQL length: 13.0 -- difference: 19.0\n",
      "Predicted SQL length: 48, Actual SQL length: 54.0 -- difference: 6.0\n",
      "Predicted SQL length: 48, Actual SQL length: 52.0 -- difference: 4.0\n",
      "Predicted SQL length: 48, Actual SQL length: 37.0 -- difference: 11.0\n",
      "Predicted SQL length: 32, Actual SQL length: 17.0 -- difference: 15.0\n",
      "Predicted SQL length: 32, Actual SQL length: 21.0 -- difference: 11.0\n",
      "Predicted SQL length: 32, Actual SQL length: 18.0 -- difference: 14.0\n",
      "Predicted SQL length: 32, Actual SQL length: 22.0 -- difference: 10.0\n",
      "Predicted SQL length: 32, Actual SQL length: 12.0 -- difference: 20.0\n",
      "Predicted SQL length: 32, Actual SQL length: 54.0 -- difference: 22.0\n",
      "Predicted SQL length: 48, Actual SQL length: 29.0 -- difference: 19.0\n",
      "Predicted SQL length: 48, Actual SQL length: 88.0 -- difference: 40.0\n",
      "Predicted SQL length: 48, Actual SQL length: 37.0 -- difference: 11.0\n",
      "Predicted SQL length: 48, Actual SQL length: 21.0 -- difference: 27.0\n",
      "Predicted SQL length: 32, Actual SQL length: 16.0 -- difference: 16.0\n",
      "Predicted SQL length: 32, Actual SQL length: 29.0 -- difference: 3.0\n",
      "Predicted SQL length: 32, Actual SQL length: 50.0 -- difference: 18.0\n",
      "Predicted SQL length: 32, Actual SQL length: 14.0 -- difference: 18.0\n",
      "Predicted SQL length: 48, Actual SQL length: 33.0 -- difference: 15.0\n",
      "Predicted SQL length: 32, Actual SQL length: 28.0 -- difference: 4.0\n",
      "Predicted SQL length: 32, Actual SQL length: 24.0 -- difference: 8.0\n",
      "Predicted SQL length: 48, Actual SQL length: 46.0 -- difference: 2.0\n",
      "Predicted SQL length: 32, Actual SQL length: 25.0 -- difference: 7.0\n",
      "Predicted SQL length: 32, Actual SQL length: 46.0 -- difference: 14.0\n",
      "Predicted SQL length: 32, Actual SQL length: 16.0 -- difference: 16.0\n",
      "Predicted SQL length: 32, Actual SQL length: 13.0 -- difference: 19.0\n",
      "Predicted SQL length: 32, Actual SQL length: 27.0 -- difference: 5.0\n",
      "Predicted SQL length: 32, Actual SQL length: 24.0 -- difference: 8.0\n",
      "Predicted SQL length: 32, Actual SQL length: 18.0 -- difference: 14.0\n",
      "Predicted SQL length: 48, Actual SQL length: 13.0 -- difference: 35.0\n",
      "Predicted SQL length: 48, Actual SQL length: 51.0 -- difference: 3.0\n",
      "Predicted SQL length: 32, Actual SQL length: 22.0 -- difference: 10.0\n",
      "Predicted SQL length: 48, Actual SQL length: 34.0 -- difference: 14.0\n",
      "Predicted SQL length: 32, Actual SQL length: 32.0 -- difference: 0.0\n",
      "Predicted SQL length: 32, Actual SQL length: 17.0 -- difference: 15.0\n",
      "Predicted SQL length: 32, Actual SQL length: 28.0 -- difference: 4.0\n",
      "Predicted SQL length: 32, Actual SQL length: 23.0 -- difference: 9.0\n",
      "Predicted SQL length: 32, Actual SQL length: 20.0 -- difference: 12.0\n",
      "Predicted SQL length: 32, Actual SQL length: 14.0 -- difference: 18.0\n",
      "Predicted SQL length: 32, Actual SQL length: 49.0 -- difference: 17.0\n",
      "Predicted SQL length: 48, Actual SQL length: 34.0 -- difference: 14.0\n",
      "Predicted SQL length: 16, Actual SQL length: 15.0 -- difference: 1.0\n",
      "Predicted SQL length: 32, Actual SQL length: 22.0 -- difference: 10.0\n",
      "Predicted SQL length: 48, Actual SQL length: 38.0 -- difference: 10.0\n",
      "Predicted SQL length: 48, Actual SQL length: 55.0 -- difference: 7.0\n",
      "Predicted SQL length: 32, Actual SQL length: 16.0 -- difference: 16.0\n",
      "Predicted SQL length: 32, Actual SQL length: 18.0 -- difference: 14.0\n",
      "Predicted SQL length: 32, Actual SQL length: 14.0 -- difference: 18.0\n",
      "Predicted SQL length: 48, Actual SQL length: 24.0 -- difference: 24.0\n",
      "Predicted SQL length: 32, Actual SQL length: 17.0 -- difference: 15.0\n",
      "Predicted SQL length: 32, Actual SQL length: 45.0 -- difference: 13.0\n",
      "Predicted SQL length: 48, Actual SQL length: 87.0 -- difference: 39.0\n",
      "Predicted SQL length: 32, Actual SQL length: 22.0 -- difference: 10.0\n",
      "Predicted SQL length: 32, Actual SQL length: 24.0 -- difference: 8.0\n",
      "Predicted SQL length: 32, Actual SQL length: 46.0 -- difference: 14.0\n",
      "Predicted SQL length: 32, Actual SQL length: 22.0 -- difference: 10.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m labels = samples[\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     logits = outputs.squeeze(\u001b[32m0\u001b[39m)\n\u001b[32m      9\u001b[39m     pred = torch.softmax(logits, dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\dynamic_context\\ContextPredictor.py:40\u001b[39m, in \u001b[36mContextPredictor.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     bert_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     cls_output = bert_out.last_hidden_state[:, \u001b[32m0\u001b[39m, :]\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.seq(cls_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:822\u001b[39m, in \u001b[36mDistilBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    820\u001b[39m         attention_mask = torch.ones(input_shape, device=device)  \u001b[38;5;66;03m# (bs, seq_length)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m822\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:587\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    579\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    580\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    581\u001b[39m         hidden_state,\n\u001b[32m   (...)\u001b[39m\u001b[32m    584\u001b[39m         output_attentions,\n\u001b[32m    585\u001b[39m     )\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m587\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    588\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    594\u001b[39m hidden_state = layer_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:531\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, x, attn_mask, head_mask, output_attentions)\u001b[39m\n\u001b[32m    528\u001b[39m sa_output = \u001b[38;5;28mself\u001b[39m.sa_layer_norm(sa_output + x)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    530\u001b[39m \u001b[38;5;66;03m# Feed Forward Network\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m ffn_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa_output\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    532\u001b[39m ffn_output: torch.Tensor = \u001b[38;5;28mself\u001b[39m.output_layer_norm(ffn_output + sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[32m    534\u001b[39m output = (ffn_output,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:466\u001b[39m, in \u001b[36mFFN.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mff_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\transformers\\pytorch_utils.py:237\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    234\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:471\u001b[39m, in \u001b[36mFFN.ff_chunk\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    469\u001b[39m x = \u001b[38;5;28mself\u001b[39m.lin1(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    470\u001b[39m x = \u001b[38;5;28mself\u001b[39m.activation(x)\n\u001b[32m--> \u001b[39m\u001b[32m471\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlin2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    472\u001b[39m x = \u001b[38;5;28mself\u001b[39m.dropout(x)\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\GitHub Repos\\LLaDAText2SQL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for samples in list(eval_dataloader):\n",
    "    input_ids = samples[\"input_ids\"]\n",
    "    attention_mask = samples[\"attention_mask\"]\n",
    "    labels = samples[\"labels\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.squeeze(0)\n",
    "        pred = torch.softmax(logits, dim=-1)\n",
    "        predictions = torch.argmax(pred, dim=-1).item()\n",
    "        predictions = FIXED_BUCKETS[predictions]\n",
    "        actuals = labels.item()\n",
    "        print(f\"Predicted SQL length: {predictions}, Actual SQL length: {actuals} -- difference: {abs(predictions - actuals)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
